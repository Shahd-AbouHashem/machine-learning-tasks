{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fkuBMBnmw6gc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "import os\n",
        "from typing import List, Dict, Any"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile, os\n",
        "\n",
        "zip_path = \"/content/ml-100k.zip\"\n",
        "extract_path = \"/content/\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "RATINGS_PATH = \"/content/ml-100k/u.data\"\n",
        "MOVIES_PATH  = \"/content/ml-100k/u.item\"\n"
      ],
      "metadata": {
        "id": "sHuo-Quhzgh3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = pd.read_csv(\n",
        "    RATINGS_PATH, sep=\"\\t\",\n",
        "    names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"],\n",
        "    engine=\"python\"\n",
        ")\n",
        "\n",
        "movies = pd.read_csv(\n",
        "    MOVIES_PATH, sep=\"|\", encoding=\"latin-1\",\n",
        "    names=[\"movieId\", \"title\"] + [f\"col{i}\" for i in range(22)],\n",
        "    usecols=[\"movieId\", \"title\"],\n",
        "    engine=\"python\"\n",
        ")\n",
        "\n",
        "movie_title = dict(zip(movies[\"movieId\"], movies[\"title\"]))\n",
        "\n",
        "def pretty_titles(movie_ids):\n",
        "    return [movie_title.get(mid, str(mid)) for mid in movie_ids]\n",
        "\n",
        "print(ratings.head())\n",
        "print(movies.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51PwNUf6xLyu",
        "outputId": "b767fe4a-ef36-4716-d19c-fffd988cffc0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   userId  movieId  rating  timestamp\n",
            "0     196      242       3  881250949\n",
            "1     186      302       3  891717742\n",
            "2      22      377       1  878887116\n",
            "3     244       51       2  880606923\n",
            "4     166      346       1  886397596\n",
            "   movieId              title\n",
            "0        1   Toy Story (1995)\n",
            "1        2   GoldenEye (1995)\n",
            "2        3  Four Rooms (1995)\n",
            "3        4  Get Shorty (1995)\n",
            "4        5     Copycat (1995)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def per_user_split(df, test_size=0.2, min_items=5):\n",
        "    trains, tests = [], []\n",
        "    for uid, g in df.groupby(\"userId\"):\n",
        "        if len(g) < min_items:\n",
        "            continue\n",
        "        tr, te = train_test_split(g, test_size=test_size)\n",
        "        trains.append(tr)\n",
        "        tests.append(te)\n",
        "    return pd.concat(trains, ignore_index=True), pd.concat(tests, ignore_index=True)\n",
        "\n",
        "train_ratings, test_ratings = per_user_split(ratings, test_size=0.2, min_items=5)\n",
        "user_item_train = train_ratings.pivot_table(index=\"userId\", columns=\"movieId\", values=\"rating\")\n",
        "user_item_train_filled = user_item_train.fillna(0.0)\n",
        "\n",
        "users  = user_item_train.index.tolist()\n",
        "items  = user_item_train.columns.tolist()\n",
        "u2i    = {u:i for i,u in enumerate(users)}\n",
        "i2pos  = {m:j for j,m in enumerate(items)}\n",
        "\n",
        "def seen_items_train(uid:int) -> set:\n",
        "    if uid not in user_item_train.index:\n",
        "        return set()\n",
        "    return set(user_item_train.loc[uid].dropna().index.tolist())\n"
      ],
      "metadata": {
        "id": "_X0fayeJzeJO"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_sim = cosine_similarity(user_item_train_filled.values)         # (U x U)\n",
        "item_sim = cosine_similarity(user_item_train_filled.values.T)       # (I x I)\n",
        "\n",
        "user_sim_row_sums = user_sim.sum(axis=1, keepdims=True)\n",
        "user_sim_row_sums[user_sim_row_sums==0] = 1.0\n",
        "user_sim_norm = user_sim / user_sim_row_sums\n",
        "\n",
        "item_sim_row_sums = item_sim.sum(axis=1, keepdims=True)\n",
        "item_sim_row_sums[item_sim_row_sums==0] = 1.0\n",
        "item_sim_norm = item_sim / item_sim_row_sums"
      ],
      "metadata": {
        "id": "0B6vqNgm51gh"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_usercf(uid:int, top_k:int=10) -> list:\n",
        "    if uid not in u2i:\n",
        "        return []\n",
        "    uidx = u2i[uid]\n",
        "    scores = user_sim_norm[uidx] @ user_item_train_filled.values\n",
        "    seen = seen_items_train(uid)\n",
        "    recs = [(m, scores[i2pos[m]]) for m in items if m not in seen]\n",
        "    recs.sort(key=lambda x: x[1], reverse=True)\n",
        "    return [m for m,_ in recs[:top_k]]\n",
        "\n",
        "def recommend_itemcf(uid:int, top_k:int=10) -> list:\n",
        "    if uid not in u2i:\n",
        "        return []\n",
        "    uidx  = u2i[uid]\n",
        "    uvec  = user_item_train_filled.values [uidx]\n",
        "    scores = uvec @ item_sim_norm\n",
        "    seen = seen_items_train(uid)\n",
        "    recs = [(m, scores[i2pos[m]]) for m in items if m not in seen]\n",
        "    recs.sort(key=lambda x: x[1], reverse=True)\n",
        "    return [m for m,_ in recs[:top_k]]\n"
      ],
      "metadata": {
        "id": "-GzMyqyK0eiT"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_usercf(uid:int, top_k:int=10) -> list:\n",
        "    if uid not in u2i:\n",
        "        return []\n",
        "    uidx = u2i[uid]\n",
        "    scores = user_sim_norm[uidx] @ user_item_train_filled.values\n",
        "    seen = seen_items_train(uid)\n",
        "    recs = [(m, scores[i2pos[m]]) for m in items if m not in seen]\n",
        "    recs.sort(key=lambda x: x[1], reverse=True)\n",
        "    return [m for m,_ in recs[:top_k]]\n",
        "\n",
        "def recommend_itemcf(uid:int, top_k:int=10) -> list:\n",
        "    if uid not in u2i:\n",
        "        return []\n",
        "    uidx  = u2i[uid]\n",
        "    uvec  = user_item_train_filled.values[uidx]\n",
        "    scores = uvec @ item_sim_norm\n",
        "    seen = seen_items_train(uid)\n",
        "    recs = [(m, scores[i2pos[m]]) for m in items if m not in seen]\n",
        "    recs.sort(key=lambda x: x[1], reverse=True)\n",
        "    return [m for m,_ in recs[:top_k]]\n"
      ],
      "metadata": {
        "id": "l33snxtZ0mU4"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BONUS - matrix factorization (SVD)\n",
        "\n",
        "user_means = user_item_train.apply(lambda row: row.mean(), axis=1).fillna(0.0).values\n",
        "R_centered = user_item_train.subtract(user_means, axis=0).fillna(0.0).values  # (U x I)\n",
        "\n",
        "rank = 50\n",
        "svd = TruncatedSVD(n_components=rank)\n",
        "U = svd.fit_transform(R_centered)       # (U x k)\n",
        "S = svd.singular_values_\n",
        "VT = svd.components_                    # (k x I)\n",
        "R_hat_centered = U @ np.diag(S) @ VT    # (U x I)\n",
        "R_hat = R_hat_centered + user_means.reshape(-1, 1)\n",
        "\n",
        "def recommend_svd(uid:int, top_k:int=10) -> list:\n",
        "    if uid not in u2i:\n",
        "        return []\n",
        "    uidx = u2i[uid]\n",
        "    scores = R_hat[uidx]\n",
        "    seen = seen_items_train(uid)\n",
        "    recs = [(m, scores[i2pos[m]]) for m in items if m not in seen]\n",
        "    recs.sort(key=lambda x: x[1], reverse=True)\n",
        "    return [m for m,_ in recs[:top_k]]\n"
      ],
      "metadata": {
        "id": "tEN1iV5L0s89"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation: Precision@K\n",
        "def precision_at_k(recommended:list, relevant:set, k:int=10) -> float:\n",
        "    if not recommended:\n",
        "        return 0.0\n",
        "    cut = recommended[:k]\n",
        "    return len(set(cut) & relevant) / k\n",
        "\n",
        "def evaluate_all(users_subset:list, k:int=10) -> dict:\n",
        "    out = {\"UserCF\": [], \"ItemCF\": [], \"SVD\": []}\n",
        "    test_rel = (\n",
        "        test_ratings.loc[test_ratings.rating >= 4, [\"userId\",\"movieId\"]]\n",
        "        .groupby(\"userId\")[\"movieId\"].apply(set)\n",
        "    )\n",
        "    for uid in users_subset:\n",
        "        if uid not in u2i or uid not in test_rel.index:\n",
        "            continue\n",
        "        relevant = test_rel.loc[uid]\n",
        "        if not relevant:\n",
        "            continue\n",
        "        out[\"UserCF\"].append(precision_at_k(recommend_usercf(uid, k), relevant, k))\n",
        "        out[\"ItemCF\"].append(precision_at_k(recommend_itemcf(uid, k), relevant, k))\n",
        "        out[\"SVD\"].append(precision_at_k(recommend_svd(uid, k), relevant, k))\n",
        "    return {k_: (float(np.mean(v)) if len(v)>0 else 0.0) for k_, v in out.items()}\n"
      ],
      "metadata": {
        "id": "ffl5O25s07D_"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample recommendations\n",
        "def pretty_titles(movie_ids:list) -> list:\n",
        "    return [movie_title.get(mid, str(mid)) for mid in movie_ids]\n",
        "\n",
        "K = 10\n",
        "sample_user = users[0]\n",
        "print(\"Sample user:\", sample_user)\n",
        "\n",
        "print(\"\\nUserCF recommendations:\")\n",
        "print(*pretty_titles(recommend_usercf(sample_user, top_k=K)), sep=\"\\n- \")\n",
        "\n",
        "print(\"\\nItemCF recommendations:\")\n",
        "print(*pretty_titles(recommend_itemcf(sample_user, top_k=K)), sep=\"\\n- \")\n",
        "\n",
        "print(\"\\nSVD recommendations:\")\n",
        "print(*pretty_titles(recommend_svd(sample_user, top_k=K)), sep=\"\\n- \")\n",
        "\n",
        "subset_size = min(200, len(users))\n",
        "eval_users = list(np.random.choice(users, size=subset_size, replace=False))\n",
        "\n",
        "results = evaluate_all(eval_users, k=K)\n",
        "print(f\"\\nPrecision @ {K} on {len(eval_users)} users\")\n",
        "for k_, v in results.items():\n",
        "    print(f\"{k_}: {v:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBhGrMN01BlX",
        "outputId": "58db416c-02ed-4ef5-a37f-e774f0f0c872"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample user: 1\n",
            "\n",
            "UserCF recommendations:\n",
            "Raiders of the Lost Ark (1981)\n",
            "- Silence of the Lambs, The (1991)\n",
            "- Fargo (1996)\n",
            "- Pulp Fiction (1994)\n",
            "- Schindler's List (1993)\n",
            "- E.T. the Extra-Terrestrial (1982)\n",
            "- Terminator, The (1984)\n",
            "- Rock, The (1996)\n",
            "- Amadeus (1984)\n",
            "- One Flew Over the Cuckoo's Nest (1975)\n",
            "\n",
            "ItemCF recommendations:\n",
            "Silence of the Lambs, The (1991)\n",
            "- Pulp Fiction (1994)\n",
            "- Raiders of the Lost Ark (1981)\n",
            "- E.T. the Extra-Terrestrial (1982)\n",
            "- Terminator, The (1984)\n",
            "- Fish Called Wanda, A (1988)\n",
            "- Stand by Me (1986)\n",
            "- Fargo (1996)\n",
            "- Get Shorty (1995)\n",
            "- Amadeus (1984)\n",
            "\n",
            "SVD recommendations:\n",
            "Silence of the Lambs, The (1991)\n",
            "- Raiders of the Lost Ark (1981)\n",
            "- Fargo (1996)\n",
            "- Secrets & Lies (1996)\n",
            "- Close Shave, A (1995)\n",
            "- Hunt for Red October, The (1990)\n",
            "- Titanic (1997)\n",
            "- Terminator, The (1984)\n",
            "- Glory (1989)\n",
            "- Rear Window (1954)\n",
            "\n",
            "Precision @ 10 on 200 users\n",
            "UserCF: 0.2035\n",
            "ItemCF: 0.2490\n",
            "SVD: 0.1758\n"
          ]
        }
      ]
    }
  ]
}